Good. Then we‚Äôll treat Postgres as the constant, and only swap the connection string between Replit and Render. Same schema, same code, same endpoints. No special ‚ÄúRender version‚Äù, just different env vars.

Below is Prompt 1 (for Replit) that tells Rapplet exactly what to build for TTS narration on cards in a way that:
	‚Ä¢	works now on Replit with Postgres
	‚Ä¢	deploys cleanly on Render later
	‚Ä¢	avoids hallucinations by locking narration text
	‚Ä¢	stores audio safely (object storage), not on ephemeral disk
	‚Ä¢	supports preview + generate + playback
	‚Ä¢	is ready for Stripe gating later (hooks included, not a full billing rebuild)

‚∏ª

Prompt 1: Add Card Narration (Text-to-Speech) with Storage + Admin Controls (Postgres)

You are working inside the existing Story Engine app (StoryFlix/Story Engine). Postgres is already connected. We are adding Text-to-Speech narration for cards.

Non-negotiables
	1.	No hallucinations / no drift: the TTS service may ONLY speak the saved narrationText on the card.
	‚Ä¢	If we auto-generate narration text, it must be generated from the card‚Äôs existing fields and then saved for the creator to edit before audio generation.
	2.	Storage must be durable: do NOT rely on saving MP3s on local filesystem for production.
	‚Ä¢	Use object storage (Cloudflare R2 preferred, S3-compatible).
	‚Ä¢	For Replit dev, it‚Äôs still okay to use R2 via env vars; do not create a local-only storage approach that breaks later.
	3.	Admin-first workflow: creators must be able to edit narration text, pick voice, preview, generate, regenerate, and delete narration.
	4.	Front UI must be able to play narration audio and show the transcript.
	5.	Keep this feature modular: it should not break existing cards/universes.

‚∏ª

Part A: Database Schema (Postgres)

Add new fields to the cards table (or equivalent Prisma model) and migrate:
	‚Ä¢	narrationEnabled boolean default false
	‚Ä¢	narrationText text nullable
	‚Ä¢	narrationVoice varchar nullable (stores chosen voice id)
	‚Ä¢	narrationSpeed numeric/float nullable (default 1.0 if set)
	‚Ä¢	narrationStatus varchar default ‚Äònone‚Äô
Allowed: none | text_ready | generating | ready | failed
	‚Ä¢	narrationAudioUrl text nullable
	‚Ä¢	narrationAudioDurationSec numeric/float nullable
	‚Ä¢	narrationUpdatedAt timestamp nullable
	‚Ä¢	narrationError text nullable

Add new fields to universes (or equivalent):
	‚Ä¢	defaultNarrationEnabled boolean default false
	‚Ä¢	defaultNarrationVoice varchar nullable
	‚Ä¢	defaultNarrationSpeed numeric/float nullable (default 1.0)
	‚Ä¢	defaultNarrationMode varchar default ‚Äòmanual‚Äô
Allowed: manual | derive_from_sceneText | derive_from_captions | ai_summarise_from_card
	‚Ä¢	narrationStyleNotes text nullable (creator guidance for wording, not for TTS)

Migration must be safe for existing rows.

‚∏ª

Part B: Voice Catalogue + Provider Abstraction

Implement a tts/ module with:
	‚Ä¢	listVoices() returns an array of voices: { id, name, previewTextHint, tags }
	‚Ä¢	synthesiseSpeech({ text, voice, speed }) returns { audioBuffer, contentType }

Provider approach

We want to support OpenAI TTS or another provider later. Build it behind an interface.

For now:
	‚Ä¢	Implement OpenAI TTS if OPENAI_API_KEY exists
	‚Ä¢	If key missing, the endpoints should return a clear error message and the UI should show ‚ÄúTTS not configured‚Äù.

Environment variables:
	‚Ä¢	OPENAI_API_KEY (optional for now, but required for actual generation)
	‚Ä¢	R2_ENDPOINT
	‚Ä¢	R2_ACCESS_KEY_ID
	‚Ä¢	R2_SECRET_ACCESS_KEY
	‚Ä¢	R2_BUCKET
	‚Ä¢	R2_PUBLIC_BASE_URL (public URL base for reading files)

Do not hardcode any secrets.

‚∏ª

Part C: Object Storage (R2 / S3-compatible)

Create storage/objectStore.ts with functions:
	‚Ä¢	putObject(key, buffer, contentType) -> returns public URL
	‚Ä¢	deleteObject(key)
	‚Ä¢	Use S3-compatible client (AWS SDK v3) configured for R2.

Key naming convention:
narration/{universeSlug or universeId}/{cardId}/{timestamp}.mp3

Store the returned public URL into cards.narrationAudioUrl.

‚∏ª

Part D: API Endpoints

Add endpoints (auth-protected for admin routes):
	1.	GET /api/tts/voices
Returns voice list + a default preview snippet.
	2.	POST /api/cards/:id/narration/text
Body: { narrationEnabled, narrationText, narrationVoice, narrationSpeed }

	‚Ä¢	Saves fields
	‚Ä¢	If narrationEnabled true and narrationText is empty, auto-fill using universe default mode:
	‚Ä¢	derive_from_sceneText => use card.sceneText
	‚Ä¢	derive_from_captions => join captions into a short narration
	‚Ä¢	ai_summarise_from_card => call LLM to produce 1 concise paragraph from existing card fields ONLY (no new facts). Save result for creator editing. Do NOT generate audio in this step.
Set narrationStatus = text_ready.

	3.	POST /api/cards/:id/narration/preview
Body: { text, voice, speed }

	‚Ä¢	Generates a short preview audio (limit text to first ~300 chars)
	‚Ä¢	Returns audio as a stream (no storage), for quick audition in admin

	4.	POST /api/cards/:id/narration/generate

	‚Ä¢	Reads card.narrationText (must exist)
	‚Ä¢	Sets status generating
	‚Ä¢	Calls TTS provider to synthesise full audio
	‚Ä¢	Uploads to R2
	‚Ä¢	Updates card:
	‚Ä¢	narrationAudioUrl, narrationStatus='ready', narrationUpdatedAt=now, clear narrationError
	‚Ä¢	On failure: narrationStatus='failed', set narrationError

	5.	DELETE /api/cards/:id/narration

	‚Ä¢	Deletes the object from R2 (if url exists)
	‚Ä¢	Clears audio url and resets status to none (keep text optional, but disable narration)

Guardrails
	‚Ä¢	Hard limit narrationText length (e.g. 2,000‚Äì3,000 chars)
	‚Ä¢	Reject generation if narrationEnabled false
	‚Ä¢	Ensure narration text originates from stored field for generate endpoint (no ad-hoc text)

‚∏ª

Part E: Admin UI Changes (must be obvious)

In the Universe admin view (list of cards):
	‚Ä¢	Add a clear ‚Äúüéô Narration‚Äù column:
	‚Ä¢	Status chip: None / Text ready / Generating / Ready / Failed
	‚Ä¢	Button: Edit (opens card edit)
	‚Ä¢	Button: Generate (only if text_ready or failed)
	‚Ä¢	Button: Play (only if ready)
Make the ‚ÄúGenerate Image‚Äù button label explicit: ‚ÄúGenerate Image‚Äù (not generic AI/magic).

In the Card edit screen:
Add a ‚ÄúNarration‚Äù panel with:
	‚Ä¢	Toggle: Enable narration
	‚Ä¢	Textarea: narrationText
	‚Ä¢	Dropdown: voice (populated from /api/tts/voices)
	‚Ä¢	Slider: speed (0.8‚Äì1.2)
	‚Ä¢	Buttons:
	‚Ä¢	Preview (5 sec)
	‚Ä¢	Save Text
	‚Ä¢	Generate Audio
	‚Ä¢	Delete Audio
	‚Ä¢	Show audio player + transcript when ready
	‚Ä¢	Show errors if failed

Also add a ‚ÄúBack to Universe‚Äù button and ensure the little ‚Äúi‚Äù icon on front UI can deep-link back to admin card edit.

‚∏ª

Part F: Front UI Playback

In the card viewer (phase 2 context card):
	‚Ä¢	If card.narrationAudioUrl exists and narrationEnabled true:
	‚Ä¢	Show play/pause
	‚Ä¢	Show transcript (narrationText)
	‚Ä¢	Do not auto-play unless the user taps (mobile restrictions)

‚∏ª

Part G: Future Stripe Paywall Hooks (don‚Äôt implement full Stripe now)

Add a simple server-side function stub:
canUseTTS(user, universeId): { allowed: boolean, reason?: string }
For now return allowed true for admin users, but wire it so we can later check plan limits.

Add a usage log table (optional but recommended):
tts_usage with: userId, universeId, cardId, charsCount, createdAt
Record usage on successful generation.

‚∏ª

Part H: Render Deployment Compatibility

All secrets must come from env vars.
Postgres uses DATABASE_URL.
R2 uses env vars listed above.
No filesystem dependency.

‚∏ª

Deliverables
	1.	DB migration + updated models
	2.	TTS module with provider abstraction
	3.	R2 object storage uploader
	4.	API endpoints
	5.	Admin UI changes
	6.	Front UI playback
	7.	Basic error handling and statuses

‚∏ª

If you implement this, we can test in Replit immediately by:
	‚Ä¢	Uploading/importing Time Spent cards
	‚Ä¢	Turning on narration for Card 1
	‚Ä¢	Preview voice
	‚Ä¢	Generate narration audio
	‚Ä¢	Confirm it plays on the front UI context card

‚∏ª

Quick sanity note (so you don‚Äôt get stung later)

Replit Postgres vs Render Postgres: same schema, just different DATABASE_URL.
The only ‚Äúnew thing‚Äù on Render is you must also provide the R2 credentials and OpenAI key in Render env vars.

‚∏ª

If you want, I‚Äôll also write Prompt 2 right after this: ‚ÄúNarration auto-fill rules + anti-hallucination QA checks + ‚Äò3-card hook‚Äô default release behaviour‚Äù so the engine stays coherent and sticky across every import.